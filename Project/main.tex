 \documentclass[10pt, journal]{IEEEtran}
\usepackage{float}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{float}
\usepackage{multirow}
\usepackage{url}

% Title and Author
\title{Explainable AI for Medical Image Diagnosis: \\ A Multi-Modal Comparative Analysis of Deep Learning Interpretability in Brain MRI}

\author{\IEEEauthorblockN{Chaitrali Joshi, Libby Li}\\
\textit{University of Waterloo}\\
\{cyjoshi, y2946li\}@uwaterloo.ca}

\begin{document}

\maketitle

\begin{abstract}
The deployment of Deep Learning (DL) in medical imaging is currently limited by the ``black-box'' nature of Convolutional Neural Networks (CNNs). While architectures like ResNet have achieved radiologist-level performance in diagnosing brain neoplasms, their opaque decision-making processes raise profound safety and ethical concerns. This study addresses these challenges through a dual-objective framework using a ResNet18\cite{resnet} architecture trained on multi-modal MRI datasets available on Kaggle.

The primary goal of this study is to perform a comparative analysis between manual radiological assessment, CNN based classification and the visual explanations generated by two Explainable AI (XAI) techniques: Gradient-weighted Class Activation Mapping (Grad-CAM) and Local Interpretable Model-agnostic Explanations (LIME). We systematically evaluate whether the features driving the CNN's predictions—such as the enhancing rim in T1-contrast images or swelling (excess fluid) in T2-weighted sequences—align with established clinical markers. Furthermore, based on our analysis of performance metrics and corresponding XAI outputs, we found that there is a critical need to use multiple contrast mechanisms synergistically; single-modality approaches often fail in clinically predictable ways, such as the ``Isointensity Trap'' in T2-weighted imaging, necessitating a multi-modal diagnostic workflow for robustness.

Secondly, we found that we can utilize this comparative analysis as a feedback loop to refine the neural network's training. Our results demonstrate that this interpretability-driven approach not only validates the model's reliance on correct features but also provides a guided tool for correcting ``Right Answer, Wrong Reason'' scenarios, which can help to bridge the gap between high-performance computing and the trust required for clinical adoption.
\end{abstract}

\begin{IEEEkeywords}
Explainable AI, Medical Imaging, MRI Physics, ResNet18, Grad-CAM, LIME, Brain Tumor Classification, Deep Learning, Clinical Decision Support.
\end{IEEEkeywords}

% -------------------------------------------------------------------------
\section{Introduction}

\subsection{The Intersection of AI and Neuroradiology}
The field of medical imaging is undergoing a paradigm shift driven by Artificial Intelligence (AI). In neuroradiology, the detection and classification of brain neoplasms—such as Gliomas, Meningiomas, and Pituitary tumors—are tasks that demand high precision and expertise. Magnetic Resonance Imaging (MRI) serves as the gold standard for this diagnosis, providing rich, multi-contrast information about soft tissue structures. However, the manual interpretation of these 3D volumetric scans is inherently labor-intensive and subject to inter-observer variability, which can delay treatment and affect patient outcomes.

Deep Learning, specifically the use of Convolutional Neural Networks (CNNs), has emerged as a powerful tool to automate this process. Models trained on massive datasets of MRI slices can detect subtle textural patterns invisible to the human eye. Yet, as these models grow in complexity—often comprising millions of parameters—they become "black boxes." In a high-stakes medical environment, a correct diagnosis without a transparent rationale is insufficient. A clinician cannot trust a system that might be classifying a tumor based on an erroneous feature, such as a watermark, a skull artifact, or image noise ("shortcuts").

\subsection{The "Black Box" Problem in Healthcare}
The lack of interpretability is the primary bottleneck preventing regulatory approval and clinical deployment of AI systems. Regulatory bodies like the FDA require validation not just of performance, but of safety and reliability. A model that achieves 99\% accuracy on a test set but fails catastrophically on an edge case in the clinic is a liability. Furthermore, the "Right to Explanation" mandated by regulations like the GDPR implies that algorithmic decisions significantly affecting users must be explainable. In medicine, this translates to a requirement that an AI diagnostic tool must provide evidence for its conclusion. If a model predicts "High-Grade Glioma," it must point to the specific anatomical regions—such as the necrotic core or the enhancing rim—that led to that conclusion.

\subsection{Research Contributions and Objectives}
This project aims to validate the "trustworthiness" of deep learning in neuroradiology by subjecting a standard CNN to rigorous interpretability auditing. We focus on two primary goals:

\begin{enumerate}
    \item \textbf{Comparative Analysis (Human vs. Machine):} To systematically compare manual radiological assessment with the visual explanations offered by two XAI techniques, Grad-CAM and LIME. We evaluate whether the CNN's "attention" aligns with established radiological physics—specifically, if it prioritizes the enhancing tumor rim in T1-contrast images and peritumoral edema in T2-weighted images, rather than relying on spurious background correlations.
    
    \item \textbf{Interpretability-Driven Feedback Loop:} To utilize the insights from the comparative analysis as a direct feedback mechanism for model improvement. By identifying "Right Answer, Wrong Reason" scenarios—where the model classifies correctly but focuses on irrelevant artifacts (e.g., skull fragments)—we aim to refine the training process and enhance the model's reliance on genuine pathological markers.
    
    \item \textbf{Robustness Across Granularity:} To validate this framework not just on broad tumor categories, but on a highly granular, 17-class dataset containing diverse and rare pathologies (e.g., Schwannomas, Neurocytomas), ensuring that the XAI explanations remain clinically valid across a wide spectrum of tumor etiologies.
\end{enumerate}

By addressing these questions, this report demonstrates how XAI can serve not merely as a visualization tool, but as an active component in developing reliable, clinically aligned diagnostic systems.

% -------------------------------------------------------------------------
\section{Related Work}

\subsection{Deep Learning in Neuroimaging}
The application of CNNs to brain tumor analysis has been extensively studied. Early approaches utilized 2D CNNs for slice-by-slice classification, while more recent works have employed 3D architectures like the V-Net and 3D U-Net\cite{unet} for volumetric segmentation. The Brain Tumor Segmentation (BraTS) challenges have been instrumental in advancing the state-of-the-art, with top-performing models typically utilizing ensembles of U-Nets. However, most of these studies focus exclusively on segmentation metrics (Dice coefficient) rather than classification or interpretability.

\subsection{Explainability in Medicine}
XAI in medicine has seen growing interest. In dermatology, studies have used saliency maps to show that CNNs classifying skin lesions often focused on rulers or ruler marks rather than the lesion itself. In radiology, Rajpurkar et al. used Class Activation Maps (CAMs) to visualize pneumonia detection in Chest X-rays (CheXNet). However, comparatively less work has been done to systematically compare different XAI methods (Gradient-based vs. Perturbation-based) specifically in the context of multi-modal MRI, where the "correct" feature changes depending on the pulse sequence (T1 vs T2).

% -------------------------------------------------------------------------
\section{Background}

% \begin{table}[!t]
% \renewcommand{\arraystretch}{1.3}
% \caption{Brief Description of Brain Tumor Types}
% \label{table_tumors}
% \centering
% \begin{tabular}{p{0.25\columnwidth} p{0.65\columnwidth}}
% \toprule
% \textbf{Tumor Type} & \textbf{Description} \\
% \midrule

% Astrocytoma & A primary glial tumor arising from astrocytes. They range from low-grade (slow-growing) to high-grade (anaplastic). \\

% Carcinoma & A secondary (metastatic) tumor that has spread from a primary cancer site elsewhere in the body (e.g., lung, breast). \\

% Ependymoma & A rare tumor arising from the ependymal cells that line the ventricles of the brain and the central canal of the spinal cord. \\

% Ganglioglioma & A rare, typically slow-growing tumor composed of a mixture of neoplastic neuronal cells (ganglion cells) and glial cells. \\

% Germinoma & A germ cell tumor, most commonly found in the pineal or suprasellar regions, predominantly affecting adolescents and young adults. \\

% Glioblastoma & The most aggressive and common form of primary malignant brain tumor (Grade IV), characterized by necrosis and vascular proliferation. \\

% Granuloma & A focal mass of inflammatory tissue resulting from chronic inflammation or infection rather than a neoplastic process. \\

% Medulloblastoma & A highly malignant, invasive embryonal tumor primarily located in the cerebellum (posterior fossa), common in children. \\

% Meningioma & A typically benign, slow-growing tumor that arises from the meninges (the protective membranes covering the brain). \\

% Neurocytoma & A rare, usually benign neuronal tumor that typically grows within the lateral ventricles (Central Neurocytoma). \\

% Oligodendroglioma & A primary glial tumor believed to originate from oligodendrocytes (myelin-producing cells) or glial precursor cells. \\

% Papilloma & A benign neuroepithelial tumor of the choroid plexus (Choroid Plexus Papilloma) that can cause hydrocephalus. \\

% Schwannoma & A benign nerve sheath tumor arising from Schwann cells, commonly affecting the vestibulocochlear nerve (Vestibular Schwannoma). \\

% Tuberculoma & A granulomatous mass caused by \textit{Mycobacterium tuberculosis} infection within the brain parenchyma. \\

% Normal & Healthy brain tissue presenting normal anatomical structures without pathological lesions or anomalies. \\

% \bottomrule
% \end{tabular}
% \end{table}

Firstly, we cover the overview of different datasets used for our experiments.
\subsection{Dataset Overview: Brain Tumor MRI Images 44 Classes}

The Brain Tumor MRI Images 44 Classes dataset \cite{KaggleBrain44} is a comprehensive, private collection of magnetic resonance imaging (MRI) scans designed for the development and evaluation of deep learning models in neuro-oncology. This dataset decribes several tumor types as shown in Table \ref{table_tumors}.

\subsubsection{Key Technical Specifications}

\begin{itemize}
    \item \textbf{Imaging Modalities:} The dataset consists of axial plane images across three primary sequences:
    \begin{itemize}
        \item \textbf{T1-weighted (T1):} Provides high anatomical detail.
        \item \textbf{Contrast-enhanced T1 (T1C+):} Highlights blood-brain barrier breakdown.
        \item \textbf{T2-weighted (T2):} High sensitivity to fluid, CSF, and peritumoral edema.
    \end{itemize}
    
    \item \textbf{Scale:} The collection contains approximately 4,449 real clinical images.
    
    \item \textbf{Class Structure:} The ``44 Classes'' naming convention refers to the granular organization of the data, where each of the 14 pathological types\cite{b5} is further subdivided by the MRI sequence (e.g., Astrocytoma T1, Astrocytoma T1C+, and Astrocytoma T2), in addition to a ``Normal'' control group for T1 and T2.
    
    \item \textbf{Pathologies Included:}
    \begin{itemize}
        \item \textit{Gliomas:} Astrocytoma, Ganglioglioma, Glioblastoma, Oligodendroglioma, and Ependymoma.
        \item \textit{Other Neoplasms:} Meningioma, Neurocytoma, Medulloblastoma, Germinoma, Papilloma, Schwannoma, and Carcinoma (Metastasis).
        \item \textit{Infectious/Inflammatory Mimics:} Granuloma and Tuberculoma.
    \end{itemize}
    
    \item \textbf{Data Integrity:} The images have been curated to ensure the complete removal of patient identification and metadata markings. All cases were interpreted and validated by professional radiologists, ensuring high-fidelity ground truth for clinical study and automated classification tasks.
\end{itemize}

\subsubsection{Use Case}

This dataset is useful for multi-class classification tasks where the objective extends beyond simple tumor detection. It enables the development of models capable of differentiating between specific histological types based on their unique signal characteristics and enhancement patterns across different MRI sequences.

\subsection{Dataset Overview: Brain Tumor MRI Images 17 Classes}

The Brain Tumor MRI Images 17 Classes dataset \cite{KaggleBrain17} is a specialized collection of clinical magnetic resonance imaging (MRI) scans. This database is designed to provide a structured framework for training machine learning models to identify specific histological subtypes and variants of intracranial lesions with high granularity.

\subsubsection{Key Technical Specifications}

\begin{itemize}
    \item \textbf{Imaging Modalities:} The database comprises 4,449 real clinical images of the skull captured in axial planes. The images are weighted across three standard sequences:
    \begin{itemize}
        \item \textbf{T1-weighted (T1):} Used for anatomical localization and structural mapping.
        \item \textbf{T1 with Contrast (T1C+):} Critical for evaluating vascularity and blood-brain barrier integrity in active tumor regions.
        \item \textbf{T2-weighted (T2):} Essential for detecting fluid-rich lesions and characterizing peritumoral edema.
    \end{itemize}
    
    \item \textbf{Taxonomy and Organization:} The dataset is organized into 17 distinct functional categories, grouping tumors and lesions by their pathological origin and grade:
    \begin{itemize}
        \item \textit{Glioma Subtypes:} Astrocytoma, Ganglioglioma, Glioblastoma, Oligodendroglioma, and Ependymoma.
        \item \textit{Meningioma Variants:} Categorized into Low Grade, Atypical, Anaplastic, and Transitional types.
        \item \textit{Neurocytoma:} Differentiated into Central (Intraventricular) and Extraventricular locations.
        \item \textit{Schwannoma:} Including Acoustic/Vestibular and Trigeminal variants.
        \item \textit{Non-Neoplastic Injuries:} This category includes Abscesses, Cysts, and Miscellaneous Encephalopathies.
        \item \textit{Control Group:} NORMAL brain scans without identified pathology.
    \end{itemize}
    
    \item \textbf{Data Privacy and Validation:} The images are derived from real medical examinations. All patient metadata and identifiers from medical records have been removed to preserve anonymity. Every exam has been interpreted and labeled by professional radiologists, providing a reliable gold standard for academic study and diagnostic modeling.
\end{itemize}

\subsubsection{Use Case}
This dataset is particularly valuable for high-granularity classification tasks. Unlike broader datasets, it allows for the differentiation of meningioma grades and the distinction between neoplastic growth and other types of injuries like abscesses, which are frequent clinical mimics in neuroradiology.

\subsubsection{Key Technical Specifications}

\begin{itemize}
    \item \textbf{Curation Goals:} The dataset is designed to mitigate common research challenges, including:
    \begin{itemize}
        \item \textbf{Class Imbalance:} Ensuring a balanced representation of both common and rare tumor types to prevent model bias.
        \item \textbf{Tumor Diversity:} Expanding the scope beyond a narrow focus on gliomas to include a wide variety of intracranial pathologies.
        \item \textbf{Annotation Consistency:} Utilizing standardized, expert-verified labels to resolve the inconsistencies often found in multi-institutional datasets.
    \end{itemize}
    
    \item \textbf{Imaging and Labeling:} 
    \begin{itemize}
        \item \textbf{High-Quality Annotations:} All images feature meticulous, expert-level labels for both whole-tumor classification and voxel-level segmentation.
        \item \textbf{Multimodal Integration:} The dataset supports multimodal analysis, providing the necessary signal variety required for state-of-the-art neural network architectures.
    \end{itemize}
\end{itemize}

\subsubsection{T1 OR T1-Weighted (Longitudinal Relaxation)}
This sequence highlights the recovery of longitudinal magnetization ($M_z$). The signal intensity $S$ is governed by:
\begin{equation}
    S \propto \rho (1 - e^{-TR/T1})
\end{equation}
where $\rho$ is proton density and $TR$ is the Repetition Time. Tissues with short T1 times, such as fat, appear bright, while water (CSF, edema) appears dark. T1 is the standard for anatomical detail.

\subsubsection{T1-Weighted Contrast-Enhanced (T1C+)}
This modality involves the administration of a paramagnetic contrast agent (typically Gadolinium-based) which shortens the T1 relaxation time of nearby protons. The effective relaxation rate $1/T1_{eff}$ increases linearly with the concentration of the contrast agent $[C]$ and its specific relaxivity $r_1$:
\begin{equation}
    \frac{1}{T1_{eff}} = \frac{1}{T1_{native}} + r_1 \cdot [C]
\end{equation}
Because $T1_{eff}$ is reduced, the term $(1 - e^{-TR/T1_{eff}})$ in the signal equation approaches 1 more rapidly. This causes tissues with blood-brain barrier breakdown (active tumor core) to appear hyperintense, distinguishing them from non-enhancing edema.

\subsubsection{T2 OR T2-Weighted (Transverse Relaxation)}
This sequence highlights the decay of transverse magnetization ($M_{xy}$). The signal is governed by:
\begin{equation}
    S \propto \rho e^{-TE/T2}
\end{equation}
where $TE$ is the Echo Time. Water and fluid-rich tissues have long T2 times and appear bright (hyperintense). This is critical for pathology detection, as most tumors and associated peritumoral edema have high water content.

\subsubsection{FLAIR (Fluid Attenuated Inversion Recovery)}
FLAIR is a T2 sequence with an inversion recovery pulse designed to null the signal from cerebrospinal fluid (CSF). The signal nulling occurs when the Inversion Time ($TI$) satisfies:
\begin{equation}
    TI = T1_{CSF} \cdot \ln(2)
\end{equation}
This results in dark ventricles but bright lesions, making it the most sensitive modality for detecting peritumoral edema and non-enhancing tumor infiltration.

% -----------------------------------------------------------------------
% TABLE I: MRI PARAMETERS
% -----------------------------------------------------------------------
\begin{table}[h]
\renewcommand{\arraystretch}{1.3}
\caption{Summary of MRI Sequence Parameters}
\label{table_mri_params}
\centering
\begin{tabular}{p{0.15\columnwidth} p{0.45\columnwidth} p{0.25\columnwidth}}
\toprule
\textbf{Seq.} & \textbf{Key Utility} & \textbf{Typical Params (ms)} \\
\midrule
\textbf{T1} & Anatomical resolution. & Short TR ($<700$) \newline Short TE ($<30$) \\
\textbf{T1C+} & Active tumor core detection. & Short TR/TE \newline + Gadolinium \\
\textbf{T2} & Edema/Pathology detection. & Long TR ($>2000$) \newline Long TE ($>80$) \\
\textbf{FLAIR} & Periventricular lesions. & Long TR/TE \newline TI ($\approx 2000-2500$) \\
\bottomrule
\end{tabular}
\end{table}
\subsection{Radiological Classification by Tumor Type}
To accurately classify brain tumors, the analyst must leverage the distinct signal patterns presented by each pathology across the three MRI sequences. The following descriptions detail the \textbf{expected} radiological appearance for each class in the dataset.

\subsubsection{Gliomas}

\begin{description}
    \item[Astrocytoma (Low Grade)] \hfill \\
    \textbf{T1:} Hypointense (dark) and often ill-defined. \\
    \textbf{T2:} Hyperintense (bright). Unlike high-grade gliomas, they typically show minimal peritumoral edema. \\
    \textbf{T1C+:} Generally non-enhancing. The absence of contrast enhancement is a key feature distinguishing low-grade astrocytomas from glioblastomas.

    \item[Glioblastoma (GBM)] \hfill \\
    \textbf{T1:} Hypointense central necrosis surrounded by an isointense irregular rim. \\
    \textbf{T2:} Heterogeneous hyperintensity with significant surrounding vasogenic edema (bright fluid signal). \\
    \textbf{T1C+:} Hallmark irregular, thick, peripheral "ring enhancement" surrounding the necrotic core. This pattern reflects rapid growth and blood-brain barrier breakdown.

    \item[Oligodendroglioma] \hfill \\
    \textbf{T1:} Hypointense cortical or subcortical mass. \\
    \textbf{T2:} Hyperintense, but often shows focal hypointense areas corresponding to calcifications (a signature feature). \\
    \textbf{T1C+:} Enhancement is variable; it can be minimal, patchy, or absent.

    \item[Ependymoma] \hfill \\
    \textbf{T1:} Isointense to hypointense, typically located within the ventricles or posterior fossa. \\
    \textbf{T2:} Hyperintense. May show "plasticity," squeezing through ventricular outlets. \\
    \textbf{T1C+:} Heterogeneous enhancement is typical.

    \item[Ganglioglioma] \hfill \\
    \textbf{T1:} Often appears as a dark cyst with a discrete isointense solid nodule. \\
    \textbf{T2:} The cystic component is extremly bright; the solid nodule is hyperintense. \\
    \textbf{T1C+:} The solid mural nodule enhances vividly, while the cyst wall typically does not.
\end{description}



\subsubsection{Non-Glial Neoplasms}

\begin{description}
    \item[Meningioma] \hfill \\
    \textbf{T1:} Isointense to gray matter (making it hard to see without contrast). \\
    \textbf{T2:} Isointense to slightly hyperintense. \\
    \textbf{T1C+:} Intense, homogeneous enhancement. A key classifying feature is the "dural tail" sign (thickening of the adjacent dura).

    \item[Schwannoma] \hfill \\
    \textbf{T1:} Isointense to hypointense, typically found in the Cerebellopontine Angle (CPA). \\
    \textbf{T2:} Hyperintense. \\
    \textbf{T1C+:} Intense, heterogeneous enhancement. Distinguishing it from meningioma often relies on location (entering the internal auditory canal).

    \item[Neurocytoma] \hfill \\
    \textbf{T1:} Isointense, typically located within the lateral ventricles near the Foramen of Monro. \\
    \textbf{T2:} Heterogeneous "bubbly" appearance due to numerous cystic spaces. \\
    \textbf{T1C+:} Moderate to strong heterogeneous enhancement.

    \item[Medulloblastoma] \hfill \\
    \textbf{T1:} Hypointense to isointense mass in the posterior fossa (cerebellum). \\
    \textbf{T2:} Isointense to variable hyperintensity. Because these tumors are densely cellular, they are often less bright on T2 than other tumors. \\
    \textbf{T1C+:} Avid, often homogeneous enhancement.

    \item[Germinoma] \hfill \\
    \textbf{T1:} Isointense to gray matter, usually suprasellar or pineal. \\
    \textbf{T2:} Isointense to hyperintense. \\
    \textbf{T1C+:} Strong, homogeneous enhancement.

    \item[Papilloma (Choroid Plexus)] \hfill \\
    \textbf{T1:} Isointense lobulated mass inside the ventricle. \\
    \textbf{T2:} Hyperintense; may show flow voids due to high vascularity. \\
    \textbf{T1C+:} Intense "frond-like" enhancement.

    \item[Carcinoma (Metastasis)] \hfill \\
    \textbf{T1:} Hypointense to isointense, often at the gray-white matter junction. \\
    \textbf{T2:} Hyperintense, usually associated with disproportionately large amounts of vasogenic edema compared to the tumor size. \\
    \textbf{T1C+:} Ring enhancement (often thinner and more regular than GBM) or solid enhancement.
\end{description}



\subsubsection{Inflammatory Mimics}

\begin{description}
    \item[Granuloma \& Tuberculoma] \hfill \\
    \textbf{T1:} Isointense to hypointense. \\
    \textbf{T2:} Variable. Caseating tuberculomas often show a hypointense (dark) core surrounded by a hyperintense rim, known as the "black target sign." \\
    \textbf{T1C+:} Ring enhancement is common. The ability to distinguish these from metastases relies heavily on the T2 appearance of the core.
\end{description}
\begin{table}[h]
\renewcommand{\arraystretch}{1.3}
\caption{MRI Signal Intensity Definitions}
\label{table_signal_intensities_transposed}
\centering
% The widths sum to roughly 0.95\columnwidth to allow for cell padding
\begin{tabular}{p{0.18\columnwidth} p{0.21\columnwidth} p{0.21\columnwidth} p{0.21\columnwidth}}
\toprule
\textbf{Feature} & \textbf{Hyperintense} & \textbf{Isointense} & \textbf{Hypointense} \\
\midrule

\textbf{Appearance} & Bright / White & Gray & Dark / Black \\

\textbf{Analogy} & Like a lightbulb & Camouflage & Like a shadow \\

\textbf{Common T2} & Water / Edema & Normal Tissue & Calcification \\

\textbf{Common T1} & Fat & Meningioma & Water / CSF \\

\bottomrule
\end{tabular}
\end{table}
\subsection{Convolutional Neural Networks: ResNet}
We train the ResNet18 model on the aforementioned datasets to utilize \textbf{transfer learning}, leveraging pre-trained weights to accelerate convergence and improve feature extraction on the limited medical imaging data. To mitigate the vanishing gradient problem in deep networks, ResNet introduces "skip connections" that allow the gradient to bypass layers.

\subsection{Explainable AI (XAI) Frameworks}

\subsubsection{Grad-CAM (Gradient-weighted Class Activation Mapping)}
Grad-CAM is a post-hoc interpretation technique \cite{gradcam} used to visualize the "attention" of the deep learning model. Instead of relying on complex mathematical abstractions, it utilizes the gradients of a target concept (e.g., 'Glioblastoma') flowing into the final convolutional layer to generate a coarse localization map. 

\textbf{Relevance to Tumor Classification:}
In our context, this technique acts as a validation layer. It produces a heatmap over the MRI slice, confirming whether the model is focusing on relevant pathological features—such as the necrotic core in T1C+ images or the peritumoral edema in T2 sequences. This ensures the classification is not driven by spurious correlations, such as skull artifacts or background noise, but rather by the specific tumor morphology.

\subsubsection{LIME (Local Interpretable Model-agnostic Explanations)}
LIME provides explanations for individual predictions by approximating the complex neural network with a simpler, interpretable surrogate model locally \cite{lime}. It assumes that while the boundary between tumor types (e.g., Meningioma vs. Schwannoma) is globally non-linear, it can be treated as linear within the immediate vicinity of a single image sample.

\textbf{Relevance to Tumor Classification:}
LIME operates by perturbing the input image—essentially masking different "superpixels" or segments of the tumor—to observe how the prediction confidence shifts. This allows us to identify the precise morphological structures driving a diagnosis. For instance, it can reveal if the model's decision was heavily influenced by a "dural tail" (characteristic of Meningioma) or a cystic component, providing a clinically interpretable rationale for the AI's output.

% -------------------------------------------------------------------------
\section{Methods and Experimental Setup}

We have previously described the datasets, neural networks as well as the methodology that an analyst typically uses to classify different brain tumor cases based on MRI slices. In this setion, we will describe in the detail the data processing pipeline and the corresponding discussion on the results of the experiments.

\subsection{Data Preprocessing Pipeline}
A standardized preprocessing pipeline was implemented using PyTorch \texttt{torchvision} transforms to ensure compatibility with the pre-trained ResNet18 architecture.

\begin{enumerate}
    \item \textbf{Input Resizing:} All MRI scans were resized to a spatial dimension of $224 \times 224$ pixels. This step is necessary to align the varied resolutions of the source datasets (17-Class and BRISC) with the fixed input layer of the ResNet model.
    
    \item \textbf{Normalization:} Pixel intensity values $I(x,y)$ were normalized using Z-score standardization based on ImageNet statistics. For each channel $c$, the normalized value is computed as:
    \begin{equation}
        I_{norm}^c = \frac{I^c - \mu_c}{\sigma_c}
    \end{equation}
    where the mean vector $\mu = [0.485, 0.456, 0.406]$ and standard deviation vector $\sigma = [0.229, 0.224, 0.225]$.
    
    \item \textbf{Input Adaptation:} The data was loaded using directory-based iterators (\texttt{ImageFolder}). To leverage the transfer learning weights from ImageNet, the grayscale MRI scans were loaded as 3-channel RGB tensors.
    
    \item \textbf{Device Allocation:} Preprocessed tensors were batched (batch size = 32) and transferred to the GPU (CUDA) for accelerated training and inference.
\end{enumerate}

\subsection{Model Architecture \& Initialization}
We utilized the ResNet18 architecture provided by the \texttt{torchvision} library. To leverage transfer learning, the model was initialized with pre-trained weights from the ImageNet-1K dataset (\texttt{IMAGENET1K\_V1}). 

The architecture was adapted for our specific multi-class task by replacing the final fully connected (linear) layer. The input features of the original final layer were preserved, while the output dimension was mapped to the number of classes ($N_{classes}$) specific to the active dataset.
\begin{equation}
    f_{fc} = \text{Linear}(in\_features=512, out\_features=N_{classes})
\end{equation}

\subsection{Training Protocol}
The model was trained using the following hyperparameters, consistent across all modality experiments:
\begin{itemize}
    \item \textbf{Loss Function:} Cross Entropy Loss, utilized for multi-class classification:
    \begin{equation}
        \mathcal{L} = - \sum_{c=1}^{M} y_{o,c} \log(p_{o,c})
    \end{equation}
    
    \item \textbf{Optimizer:} Adam algorithm\cite{adam} was employed for gradient descent optimization.
    \begin{itemize}
        \item Learning Rate: $1 \times 10^{-4}$
        \item Betas: Default $(\beta_1=0.9, \beta_2=0.999)$
    \end{itemize}
    
    \item \textbf{Training Schedule:} The training loop was set for a fixed duration of 5 epochs per modality experiment to mitigate overfitting given the limited dataset size.
    
    \item \textbf{Compute Environment:} Training and inference were executed on an NVIDIA GPU (CUDA enabled) to accelerate tensor operations.
\end{itemize}
% -------------------------------------------------------------------------
\section{Results and Analysis}
\subsection{Brain Tumor MRI Images 17 Classes across 6 Groups}
The proposed dataset \cite{KaggleBrain17} comprises 4,449 anonymized, axial-plane MRI scans of the cranium, utilizing T1-weighted, contrast-enhanced T1, and T2-weighted sequences. These images, derived from actual clinical examinations and verified by radiologists, are organized into six primary diagnostic categories:

\begin{itemize}
    \item \textbf{Glioma:} Including Astrocytoma, Ganglioglioma, Glioblastoma, Oligodendroglioma, and Ependymoma.
    \item \textbf{Meningioma:} Covering Low Grade, Atypical, Anaplastic, and Transitional types.
    \item \textbf{Neurocytoma:} Grouping Central (Intraventricular) and Extraventricular variants.
    \item \textbf{Normal:} Representing healthy brain tissue.
    \item \textbf{Other Lesions:} Encompassing Abscesses, Cysts, and miscellaneous Encephalopathies.
    \item \textbf{Schwannoma:} Including Acoustic and Vestibular-Trigeminal types.
\end{itemize}

To ensure ethical compliance and patient privacy, all personal metadata has been removed from the files.
\begin{figure*}[ht]
    \centering
    % Replace 'filename' with your actual image file name (e.g., hierarchy_diagram.png)
    % The width is set to 0.8 of the text width to ensure it fits nicely
    \includegraphics[width=0.8\textwidth]{T1_CM_17c.png}
    \caption{Confusion Matrix for T1 (6 diagnostic groups)}
    \label{fig:t1_cm_17c}
\end{figure*}
\begin{figure*}[ht]
    \centering
    % Replace 'filename' with your actual image file name (e.g., hierarchy_diagram.png)
    % The width is set to 0.8 of the text width to ensure it fits nicely
    \includegraphics[width=0.8\textwidth]{T1C_CM_17c.png}
    \caption{Confusion Matrix for T1C+ (6 diagnostic groups)}
    \label{fig:t1c_cm_17c}
\end{figure*}
\begin{figure*}[ht]
    \centering
    % Replace 'filename' with your actual image file name (e.g., hierarchy_diagram.png)
    % The width is set to 0.8 of the text width to ensure it fits nicely
    \includegraphics[width=0.8\textwidth]{T2_CM_17c.png}
    \caption{Confusion Matrix for T2 (6 diagnostic groups)}
    \label{fig:t2_cm_17c}
\end{figure*}

Below is the summary of how each of the modalities were used to classify different tumor types. See Table \ref{tab:modality_synergy}
\begin{table}[ht]
\centering
\caption{Synergistic Role of MRI Modalities by Tumor Type}
\label{tab:modality_synergy}
\renewcommand{\arraystretch}{1.4}
\begin{tabular}{p{0.2\linewidth} p{0.21\linewidth} p{0.21\linewidth} p{0.2\linewidth}}
\toprule
\textbf{Tumor Type} & \textbf{Primary Detection} \newline \textit{(Highest Sensitivity/Recall)} & \textbf{Primary Confirmation} \newline \textit{(Highest Specificity/Precision)} & \textbf{Synergy Strategy} \\ 
\midrule

\textbf{Neurocytoma} & \textbf{T2} (Recall 1.00) \newline \textit{Catches all cases} & \textbf{T1C+} (Precision 1.00) \newline \textit{Eliminates false positives} & \textbf{Screen \& Verify:} Use T2 to flag; T1C+ to confirm. \\ 
\hline

\textbf{Meningioma} & \textbf{T1C+} (Recall 0.99) \newline \textit{Highlights contrast uptake} & \textbf{T1} (Precision 0.99) \newline \textit{Checks anatomical shape} & \textbf{High Sensitivity:} T1C+ ensures no tumor is missed. \\ 
\hline

\textbf{Other Lesions} \newline \textit{(Cysts/Abscess)} & \textbf{T1C+ / T2} (Recall 1.00) \newline \textit{Fluid/Rim signals} & \textbf{T1C+} (Precision 1.00) \newline \textit{Rim enhancement specific} & \textbf{Dual-Check:} Fluid (T2) + Rim (T1C+) confirms diagnosis. \\ 
\hline

\textbf{Glioma} & \textbf{T1} (Recall 1.00) \newline \textit{Morphological distortion} & \textbf{T1} (Precision 0.99) \newline \textit{Mass effect} & \textbf{T1 Dominance:} T1 acts as primary; T1C+ supports. \\ 
\hline

\textbf{Schwannoma} & \textbf{T1} (Recall 1.00) \newline \textit{Location/Shape} & \textbf{T1} (Precision 0.96) \newline \textit{Spatial features} & \textbf{Anatomical Focus:} T1 shape analysis outperforms signal. \\ 

\bottomrule
\end{tabular}
\end{table}

Figure \ref{fig:t1_cm_17c}, Figure \ref{fig:t1c_cm_17c} and Figure \ref{fig:t2_cm_17c} show the confusion matrices for classification when using T1, T1C+ and T2 modalities respectively.

\subsubsection{Machine Vision Analysis for 6 Diagnostic Groups}

Based on the comprehensive performance metrics and Explainable AI (XAI) visualizations observed in this study, the AI's behavior closely mirrors the clinical ``Search, Characterize, and Verify'' workflow utilized by radiologists. However, the XAI backed analysis also reveals a distinct ``machine vision'' shortcut specific to the T1 modality that qualifies for model improvement.
\\\\
\noindent
\textbf{The ``Wide Net'' Strategy (Detection via T2):}
\textbf{Radiologist Workflow:} Clinicians typically prioritize T2-weighted sequences for initial detection because fluid and edema appear as bright signals, acting as a high-sensitivity ``beacon'' for pathology.

\textbf{AI Alignment:} The model utilizes the T2 modality primarily for \textbf{Sensitivity (Recall)}.
\begin{itemize}
    \item For Neurocytomas and Other Lesions (Cysts/Abscesses), the T2 modality achieved \textbf{100\% Recall}, successfully flagging every single instance.
\end{itemize}

\textbf{Visual Evidence:} The Grad-CAM visualizations for T2 demonstrate the model focusing on the diffuse area of edema surrounding the tumor rather than the tumor core itself. This confirms the model relies on the ``bright spot'' signal to ensure no pathology is missed.
\\\\
\textbf{The ``Validator'' Strategy (Confirmation via T1C+)}
\textbf{Radiologist Workflow:} Once a lesion is detected, radiologists switch to T1-Contrast (T1C+) to characterize it, looking for tissue enhancement to confirm malignancy and define boundaries.

\textbf{AI Alignment:} The model utilizes T1C+ for \textbf{Specificity (Precision)}.
\begin{itemize}
    \item For Neurocytomas, the T1C+ modality achieved \textbf{100\% Precision}, acting as a filter to eliminate false positives found by the T2 scan.
    \item For Meningiomas, the model achieved \textbf{99\% Recall}, aligning with the clinical reliance on contrast to visualize these often subtle tumors.
\end{itemize}

\textbf{Visual Evidence:} In contrast to the diffuse focus seen in T2, the T1C+ Grad-CAM visualizations tightly contour the ring-enhancing tumor core. This proves the model is characterizing the active tumor tissue, distinguishing it from surrounding fluids.
\\\\
\noindent
\textbf{Clinical Validation of Blind Spots (The ``Isointensity Trap'')}
The strongest validation of the AI's alignment with human vision is demonstrated by its failure in a clinically predictable scenario.

\begin{figure*}[ht]
    \centering
    % Replace 'filename' with your actual image file name (e.g., hierarchy_diagram.png)
    % The width is set to 0.8 of the text width to ensure it fits nicely
    \includegraphics[width=0.8\textwidth]{T2_NORMAL_VS_mennigioma.png}
    \caption{Meningioma classified as NORMAL}
    \label{fig:t2_normal_vs_mg}
\end{figure*}
\begin{itemize}
    \item \textbf{The Error:} The model failed to detect a Meningioma on the T2 scan, misclassifying it as \texttt{NORMAL}. See Figure \ref{fig:t2_normal_vs_mg}.
    \item \textbf{Clinical Explanation:} Meningiomas are often ``isointense'' (sharing the same gray scale as healthy brain) on T2 sequences. Without contrast dye (T1C+), both the human eye and the AI struggle to distinguish the tumor from normal tissue, validating that T2 cannot be used in isolation for this specific tumor type. This analysis also confirmed via XAI techniques' output for this case highlights the fact that several contrast mechanisms need to be used in conjunction to harden the diagnosis. The heatmaps of Grad-CAM as well as boundaries outlined by LIME are not able to segment the tumor.
\end{itemize}
\\\\
\noindent
\textbf{The Divergence: The ``T1 Paradox''}:
\newline
While the T2 and T1C+ modalities align with radiological practice, the Plain T1 modality exhibits a clear ``Machine Vision'' shortcut.

\textbf{Radiologist Workflow:} Plain T1 scans are seldom used for primary diagnosis as they lack the tissue contrast inherent to T2 or T1C+.

\textbf{AI Behavior:} The model \textbf{unexpectedly} performed best on plain T1, achieving \textbf{99\% Accuracy}. The XAI based analysis helps us to confirm that we don't rely on such \textbf{unexplainable} accuracy because XAI's explanation does not align with the method followed by radiologists but it rather points to a shortcut which is not in conformance with radiologists' methods.

\textbf{Visual Explanation:} The XAI evidence suggests the model is detecting anatomical distortion (mass effect) and ventricle asymmetry rather than characterizing the tumor texture itself. While statistically effective, this represents a \textbf{geometric shortcut} that differs fundamentally from the tissue-based analysis performed by radiologists.

\subsection{Brain Tumor MRI Images 44 Classes}
This dataset has a collection of T1, contrast-enhanced T1 (T1C+), and T2 magnetic resonance images separated by brain tumor type. Images are without any type of marking or patient identification, interpreted by radiologists and provided for study purposes. The images are separated by astrocytoma, carcinoma, ependymoma, ganglioglioma, germinoma, glioblastoma, granuloma, medulloblastoma, meningioma, neurocytoma, oligodendroglioma, papilloma, schwannoma and tuberculoma.

\begin{table}[ht]
\centering
\caption{Synergistic Role of MRI Modalities by Tumor Type (Based on 44-Class Study)}
\label{tab:modality_synergy}
\renewcommand{\arraystretch}{1.4}
\begin{tabular}{p{0.2\linewidth} p{0.21\linewidth} p{0.21\linewidth} p{0.2\linewidth}}
\toprule
\textbf{Tumor Type} & \textbf{Primary Detection} \newline \textit{(Highest Sensitivity/Recall)} & \textbf{Primary Confirmation} \newline \textit{(Highest Specificity/Precision)} & \textbf{Synergy Strategy} \\ 
\midrule

\textbf{Neurocytoma} & \textbf{T1 / T2} (Recall 1.00) \newline \textit{Perfect detection rate} & \textbf{T1 / T2} (Precision 1.00) \newline \textit{Zero false positives} & \textbf{Dual-Verify:} T1 and T2 agree perfectly; T1C+ is less reliable here. \\ 
\hline

\textbf{Meningioma} & \textbf{T1C+} (Recall 1.00) \newline \textit{Catches every tumor} & \textbf{T1} (Precision 0.93) \newline \textit{Filters mimics via anatomy} & \textbf{Sensitive Filter:} Use T1C+ to find candidates; T1 to confirm location. \\ 
\hline

\textbf{Granuloma} \newline \textit{(Infection)} & \textbf{T1C+} (Recall 1.00) \newline \textit{Essential for detection} & \textbf{T1} (Precision 1.00) \newline \textit{Confirms morphology} & \textbf{Contrast Dependent:} T2 fails (Recall 0.50); T1C+ is mandatory. \\ 
\hline

\textbf{Glioblastoma} & \textbf{T1C+ / T2} (Recall 1.00) \newline \textit{Edema and Enhancement} & \textbf{T1C+ / T2} (Precision 1.00) \newline \textit{Distinct features} & \textbf{Multi-Modal Lock:} Unanimous agreement across contrast and fluid scans. \\ 
\hline

\textbf{Schwannoma} & \textbf{T2} (Recall 1.00) \newline \textit{Hyperintense signal} & \textbf{T2} (Precision 0.96) \newline \textit{Outperforms T1C+} & \textbf{Signal Dominance:} T2 "lightbulb" sign is the strongest predictor. \\ 

\bottomrule
\end{tabular}
\end{table}

\subsection{Clinical Alignment and Machine Vision Analysis}

Based on the performance metrics and XAI visualizations observed in this study, the model's behavior largely aligns with the standard radiological ``Search and Verify'' workflow, particularly for malignant and infectious lesions. However, the model exhibits a distinct ``Machine Vision'' deviation in its heavy reliance on T2 for Schwannomas and plain T1 for Meningiomas.
\\
\noindent
\textbf{Alignment with Radiologist Workflow}

\textbf{The ``Contrast Necessity'' for Infection (Granuloma/Tuberculoma):}
\begin{itemize}
    \item \textbf{Clinical Reality:} Radiologists rely heavily on T1-Contrast (T1C+) to find infectious lesions (Granulomas) because they are often small and isointense on non-contrast scans.
    \item \textbf{Model Alignment:} The model failed significantly on T2 for Granulomas (Recall 0.50), missing half the cases. However, on T1C+, it achieved perfect detection (Recall 1.00). This confirms the AI, like a radiologist, requires contrast to detect these subtle pathologies.
\end{itemize}

\textbf{The ``Dual-Signal'' for Malignancy (Glioblastoma):}
\begin{itemize}
    \item \textbf{Clinical Reality:} Glioblastomas are characterized by necrotic cores (T1C+ rim enhancement) and massive edema (T2 hyperintensity).
    \item \textbf{Model Alignment:} The model achieved perfect 1.00 Precision and Recall on both T1C+ and T2 for Glioblastomas. The XAI confirms this dual attention: T1C+ visualizations focus on the ring, while T2 visualizations highlight the fluid spread.
\end{itemize}
\\\\
\noindent
\textbf{Deviations \& XAI Explanations}

\noindent
\textbf{Deviation: The T2 Dominance for Schwannomas}
\begin{itemize}
    \item \textbf{Observation:} Clinically, T1C+ is the gold standard for Schwannomas. However, the model performed best on T2 (Precision 0.96, Recall 1.00), outperforming T1C+ (Precision 0.93).
    \item \textbf{XAI Explanation:} Schwannomas appear as extremely bright, ``lightbulb-like'' signals in the cerebellopontine angle on T2 images. The XAI visualizations demonstrate the model locking onto this intense brightness. The model likely found this ``bright spot'' feature easier to learn than the complex enhancement patterns on T1C+.
\end{itemize}

\noindent
\textbf{Deviation: T1 Anatomy vs. T1C+ Signal for Meningiomas}
\begin{itemize}
    \item \textbf{Observation:} While T1C+ had perfect Recall (1.00) for Meningiomas (finding them all), it had lower Precision (0.91). Surprisingly, plain T1 had higher Precision (0.93).
    \item \textbf{XAI Explanation:} Meningiomas are ``extra-axial'' (outside the brain). The XAI for T1 shows the model tracking the physical deformation of the brain's edge. The model uses plain T1 to check the geometry of the skull boundary—a ``Machine Vision'' shortcut that is more precise than measuring contrast uptake, which can sometimes be confused with blood vessels.
\end{itemize}
% Figure \ref{fig:t1_cm_44c}, Figure \ref{fig:t1c_cm_44c} and Figure \ref{fig:t2_cm_44c} show the confusion matrices for classification when using T1, T1C+ and T2 modalities respectively.

\subsection{Explainable Analysis of Model Failure}

\begin{figure*}[ht]
    \centering
    % Replace 'filename' with your actual image file name (e.g., hierarchy_diagram.png)
    % The width is set to 0.8 of the text width to ensure it fits nicely
    \includegraphics[width=0.8\textwidth]{T2_mennigiomavs_normal.png}
    \caption{False Positive - Meningioma}
    \label{fig:false_positive}
\end{figure*}
As shown in Figure \ref{fig:false_positive}, the model produced a false positive by classifying a normal T2-weighted brain MRI as meningioma. Explainable AI (XAI) methods are tried to investigate the underlying cause of this error and to characterize the model’s decision-making process.

Grad-CAM analysis revealed diffuse and non-localized activation across central brain regions, rather than focused attention on anatomically plausible tumor locations such as extra-axial, dural-based regions. This lack of spatial specificity indicates that the model did not identify a candidate lesion consistent with meningioma pathology.

LIME further demonstrated that the prediction was influenced by superpixels corresponding to non-diagnostic image features, including skull boundaries and peripheral anatomical structures. These regions do not carry clinical relevance for meningioma detection, suggesting that the model relied on spurious correlations and global appearance cues rather than pathological features.

Together, these XAI findings explain the model failure as a mismatch between learned features and clinically valid reasoning. The error is attributable to shortcut learning and mislocalized attention, rather than subtle or ambiguous pathology. This analysis supports safe rejection of the model output and provides guidance for future model improvements, including lesion-centric supervision and preprocessing strategies to remove non-brain cues.

% \begin{figure*}[ht]
%     \centering
%     % Replace 'filename' with your actual image file name (e.g., hierarchy_diagram.png)
%     % The width is set to 0.8 of the text width to ensure it fits nicely
%     \includegraphics[width=0.8\textwidth]{T1_CM_44c.png}
%     \caption{Confusion Matrix for T1}
%     \label{fig:t1_cm_44c}
% \end{figure*}
% \begin{figure*}[ht]
%     \centering
%     % Replace 'filename' with your actual image file name (e.g., hierarchy_diagram.png)
%     % The width is set to 0.8 of the text width to ensure it fits nicely
%     \includegraphics[width=0.8\textwidth]{T1C_CM_44c.png}
%     \caption{Confusion Matrix for T1C+}
%     \label{fig:t1c_cm_44c}
% \end{figure*}
% \begin{figure*}[ht]
%     \centering
%     % Replace 'filename' with your actual image file name (e.g., hierarchy_diagram.png)
%     % The width is set to 0.8 of the text width to ensure it fits nicely
%     \includegraphics[width=0.8\textwidth]{T2_CM_44c.png}
%     \caption{Confusion Matrix for T2}
%     \label{fig:t2_cm_44c}
% \end{figure*}

\subsection{Need for Combined Usage of Contrast Mechanisms}
The need for combined usage of contrast mechanisms was seen when we examine performance metrics and corresponding explanations of by XAI techniques. By applying Grad-CAM and LIME across modalities, we see distinct ``attention fingerprints'' that help for conclusive analysis on how each MRI sequence contributes to the final diagnosis:

\begin{itemize}
    \item \textbf{Visualizing the ``Isointensity Trap'':}
    As shown in Figure \ref{fig:recall_by_modality}, Quantitative metrics indicated a performance drop for Meningiomas on T2 sequences (Recall 0.92 vs. 1.00 on T1C+). XAI visualizations revealed the root cause: on T2-weighted images, the model's attention maps were diffuse or focused on non-tumorous regions, confirming that the tumor was isointense and effectively invisible to the network. In contrast, T1C+ visualizations showed tight, high-confidence contours around the contrast-enhancing lesion. This visual dichotomy provided the evidence required to establish T1C+ as the mandatory ``validator'' for this class.
    
    \item As shown in Figure \ref{fig:neurocytoma_synergy}, there's a need for utilizing multiple contrast mechanisms for diagnosing neurocytoma.
    
    \item \textbf{Exposing Anatomical Shortcuts (Plain T1):}
    Unexpectedly high performance on plain T1 images was explained by LIME superpixels, which frequently highlighted ventricular asymmetry and midline shifts rather than tissue texture. This revealed a structural synergy: the model uses plain T1 to assess mass effect (geometry), complementing the textural analysis provided by T2 and T1C+. The heatmaps for F1 scores as shown in Figure \ref{fig:synergy_heatmap} confirm the need for utilizing multiple contrast mechnisms.
\end{itemize}

These visual insights transformed the "black box" metrics into a clinically interpretable strategy, confirming that robust diagnosis requires the fusion of \textit{anatomical} (T1), \textit{pathological} (T1C+), and \textit{fluid-based} (T2) visual evidence.
\begin{figure*}[ht]
    \centering
    % Replace 'filename' with your actual image file name (e.g., hierarchy_diagram.png)
    % The width is set to 0.8 of the text width to ensure it fits nicely
    \includegraphics[width=0.8\textwidth]{recall_by_modality.png}
    \caption{Recall By Modality}
    \label{fig:recall_by_modality}
\end{figure*}
\begin{figure*}[ht]
    \centering
    % Replace 'filename' with your actual image file name (e.g., hierarchy_diagram.png)
    % The width is set to 0.8 of the text width to ensure it fits nicely
    \includegraphics[width=0.8\textwidth]{neurocytoma_synergy.png}
    \caption{Screening and Confirmation}
    \label{fig:neurocytoma_synergy}
\end{figure*}
\begin{figure*}[ht]
    \centering
    % Replace 'filename' with your actual image file name (e.g., hierarchy_diagram.png)
    % The width is set to 0.8 of the text width to ensure it fits nicely
    \includegraphics[width=0.8\textwidth]{synergy_heatmap.png}
    \caption{Synergy Heatmap}
    \label{fig:synergy_heatmap}
\end{figure*}
% -------------------------------------------------------------------------
\section{Discussion}
\subsection{Bridging the Gap with XAI}
This project demonstrates that deep learning models need not remain inscrutable "black boxes." By applying Grad-CAM and LIME side-by-side, we established a rigorous verification framework. The study results confirm that these two distinct XAI methods consistently converge on the same anatomical regions for correct classifications. For instance, in Glioblastoma T1C+ cases, both methods tightly contoured the necrotic core, confirming that the model's high precision (1.00) is based on relevant pathological features rather than background artifacts. This dual-verification builds the necessary trust for clinical adoption.

\subsection{Clinical Implications: A Synergistic Workflow}
The performance data suggests that the AI does not just classify; it replicates the "Search and Verify" workflow of a radiologist. The model demonstrated that modalities should be used synergistically rather than in isolation:
\begin{itemize}
    \item \textbf{The "Safety Net" (T2):} The model utilized T2-weighted images as a high-sensitivity screening tool, achieving 100\% Recall for Neurocytomas. This implies an AI tool could use T2 to flag potential abnormalities ("The Wide Net") to ensure no pathology is missed.
    \item \textbf{The "Validator" (T1C+):} For infectious lesions like Granulomas and Tuberculomas, the model relied heavily on T1-Contrast, achieving perfect accuracy where non-contrast modalities failed. This suggests the AI can act as a decision support tool, prompting clinicians to order contrast scans when ambiguous features are detected on native T1/T2.
\end{itemize}

\subsection{Automation Bias vs. Algorithm Aversion}
Implementing XAI helps mitigate specific psychological risks identified in our error analysis:
\begin{itemize}
    \item \textbf{Mitigating Algorithm Aversion:} Clinicians often distrust AI due to "black box" opacity. By visualizing the model's focus—such as the "lightbulb" signal it detected for Schwannomas on T2—we provide the "why" behind the diagnosis, bridging the gap between statistical probability and clinical reasoning.
    \item \textbf{Combating Automation Bias:} The study revealed a critical "Isointensity Trap" where the model misclassified a Meningioma as \texttt{NORMAL} on a T2 scan. Without XAI, a clinician might blindly accept this "Normal" result. However, seeing an empty/diffuse heatmap alerts the radiologist that the AI failed to "see" the tumor due to lack of contrast, prompting manual intervention.
\end{itemize}

\subsection{Limitations}
\begin{itemize}
    \item \textbf{2D Analysis:} MRI is inherently 3D. Our slice-by-slice analysis ignores volumetric context, which is particularly limiting for tumors like Neurocytomas that are defined by their intraventricular location across multiple planes.
    \item \textbf{Granular Data Imbalance:} While the model performed perfectly on common classes, the 44-class granular analysis revealed struggles with rare subtypes. For example, \texttt{Ganglioglioma T1} achieved a Recall of only 0.67 compared to 1.00 for \texttt{Glioblastoma T1}, highlighting the difficulty of training deep networks on rare pathologies with limited samples.
    \item \textbf{Resolution Constraints:} Resizing images to $224 \times 224$ results in the loss of fine textural details necessary for grading. This likely contributed to the model's reliance on anatomical distortion in plain T1 images rather than subtle tissue characterization.
\end{itemize}
% -------------------------------------------------------------------------
\section{Conclusion and Future Work}
We have developed and verified a transparent ML pipeline for brain tumor diagnosis that bridges the gap between deep learning performance and clinical interpretability. By modifying the ResNet architecture to support advanced gradient analysis, we demonstrated that the model's high precision—particularly the 1.00 precision achieved for Glioblastoma on T1C+ and Neurocytoma on T2—is rooted in the correct identification of underlying MRI contrast physics rather than background artifacts. The extension of our study to a highly granular 44-class dataset confirms that these interpretability findings hold true even for diverse and complex tumor etiologies, although it also highlighted specific challenges in rare subtypes such as Gangliogliomas where recall dropped to 0.67.

Furthermore, our dual-verification approach using both Grad-CAM and LIME revealed a critical ``synergistic workflow'' where the model effectively utilizes T2 as a high-sensitivity screening tool (100\% recall for multiple classes) and T1C+ as a high-specificity validator. This mirrors standard radiological practice and suggests the model has learned to replicate human-like search patterns.

In the future, we plan to evaluate our findings in this report for\textbf{vision transformers}\cite{dosovitskiy2021vit} as well as frameworks such as SpikeNet\cite{delorme2003spikenet} which have incorporated explainability. 
% -------------------------------------------------------------------------
\section*{Acknowledgment}
The authors acknowledge the use of Google Colab Pro computational resources and the public datasets provided by Kaggle contributors as cited.

\begin{thebibliography}{00}
\bibitem{adam} D. P. Kingma and J. Ba, "Adam: A Method for Stochastic Optimization," \textit{ICLR}, 2015.

\bibitem{KaggleBrain44}
F. Feltrin, ``Brain Tumor MRI Images 44 Classes,'' Kaggle Dataset, 2023. [Online]. Available: https://www.kaggle.com/datasets/fernando2rad/brain-tumor-mri-images-44c

\bibitem{KaggleBrain17}
F. Feltrin, ``Brain Tumor MRI Images 17 Classes,'' Kaggle Dataset, 2023. [Online]. Available: https://www.kaggle.com/datasets/fernando2rad/brain-tumor-mri-images-17-classes

\bibitem{b5} J. Cheng et al., "Enhanced Performance of Brain Tumor Classification via Tumor Region Augmentation and Partition," \textit{PLoS ONE}, 2015.

\bibitem{resnet} K. He, X. Zhang, S. Ren, and J. Sun, "Deep Residual Learning for Image Recognition," \textit{CVPR}, 2016.

\bibitem{lime} M. T. Ribeiro, S. Singh, and C. Guestrin, "Why Should I Trust You?: Explaining the Predictions of Any Classifier," \textit{ACM SIGKDD}, 2016.

\bibitem{unet} O. Ronneberger et al., "U-Net: Convolutional Networks for Biomedical Image Segmentation," \textit{MICCAI}, 2015.

\bibitem{gradcam} R. R. Selvaraju et al., "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization," \textit{Proc. IEEE Int. Conf. Comp. Vis.}, 2017.

\bibitem{delorme2003spikenet}
A.~Delorme, J.~Gautrais, R.~VanRullen, and S.~Thorpe, 
\emph{SpikeNET: An Event-driven Simulation Package for Modelling Large Networks of Spiking Neurons}, 
Network: Computation in Neural Systems, vol.~14, no.~4, pp. 613--629, 2003.

\bibitem{dosovitskiy2021vit}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai, T.~Unterthiner, 
M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, J.~Uszkoreit, and N.~Houlsby, 
\emph{An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
in International Conference on Learning Representations (ICLR), 2021.

\end{thebibliography}

\end{document}